{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kader43/Apprentissage-Statistique/blob/main/FNN_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgmEprCXIUgj"
      },
      "source": [
        "# A first look at a neural network\n",
        "## Application to the MNIST classification problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hdXvLcTIUgl"
      },
      "source": [
        "Nous allons maintenant examiner un premier exemple concret de réseau de neurones, utilisant la bibliothèque Python Keras pour apprendre à classifier des chiffres manuscrits.\n",
        "\n",
        "À moins d'avoir déjà une expérience avec Keras ou des bibliothèques similaires, vous ne comprendrez pas immédiatement tous les aspects de ce premier exemple. Vous n'avez probablement même pas encore installé Keras. Ne vous inquiétez pas, c'est tout à fait normal.\n",
        "\n",
        "Le problème que nous cherchons à résoudre ici est la classification d'images en niveaux de gris de chiffres manuscrits (28 pixels par 28 pixels) dans leurs 10 catégories (de 0 à 9). Le jeu de données que nous utiliserons est le jeu de données MNIST, un jeu de données classique dans le domaine de l'apprentissage automatique, qui existe depuis presque aussi longtemps que le domaine lui-même et qui a fait l'objet de nombreuses études. Il s'agit d'un ensemble de 60 000 images d'entraînement et de 10 000 images de test, rassemblées par le National Institute of Standards and Technology (le NIST dans MNIST) dans les années 1980. On peut considérer la résolution de MNIST comme le « Hello World » de l'apprentissage profond : c'est ce que l'on fait pour vérifier que ses algorithmes fonctionnent comme prévu. En devenant un expert en apprentissage automatique, vous rencontrerez fréquemment MNIST dans les articles scientifiques, les billets de blog, etc.\n",
        "\n",
        "![Exemples MNIST](data/MNISTsample.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "scrolled": true,
        "id": "MjvIUo1XIUgl"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN9HaKYAIUgm"
      },
      "source": [
        "Le jeu de données MNIST est préchargé dans Keras, sous la forme d'un ensemble de quatre tableaux Numpy :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kPaaenDPIUgn"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwniaJO2IUgn"
      },
      "source": [
        "Les ensembles `train_images` et `train_labels` constituent l'ensemble d'entraînement, c'est-à-dire les données sur lesquelles le modèle apprendra. Le modèle sera ensuite testé sur l'ensemble de test, composé des ensembles `test_images` et `test_labels`. Nos images sont encodées sous forme de tableaux NumPy, et les étiquettes sont simplement un tableau de chiffres, allant de 0 à 9. Il existe une correspondance biunivoque entre les images et les étiquettes.\n",
        "\n",
        "Examinons maintenant les données d'entraînement :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj6uUotUIUgo",
        "outputId": "08e4d710-a5b3-4244-86b1-43d29d463120"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "train_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwU4oDWzIUgp",
        "outputId": "1d1bfa17-3e4f-4793-82e7-40f1e2f04ecb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "len(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "m18YW_61IUgp",
        "outputId": "1392c176-1614-4ef6-c9d0-8982bab23c03"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5 0 4 1 9 2 1 3 1 4]\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "#Plot the first 10 samples from the training set\n",
        "fig, ax = plt.subplots(nrows=2, ncols=5, sharex=True, sharey=True,)\n",
        "ax = ax.flatten()\n",
        "for i in range(10):\n",
        "    ax[i].imshow(train_images[i,:,:],cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "\n",
        "\n",
        "ax[0].set_xticks([])\n",
        "ax[0].set_yticks([])\n",
        "plt.tight_layout()\n",
        "# plt.savefig('./figures/mnist_all.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "print(train_labels[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fcUxs4JIUgq",
        "outputId": "d47937be-dffd-46bc-acb6-a0cd4b81d2a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "train_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-4T6DpVIUgq"
      },
      "source": [
        "Examinons les données de test :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33-CNW3uIUgq",
        "outputId": "4ea3791a-6840-4cf6-9d48-2fa8370bcf97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "test_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AS0VBH72IUgq",
        "outputId": "1f4ef67a-ff50-4754-a3f3-ffb180c8aee0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "len(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0XdUBYQIUgq",
        "outputId": "6d90a6c9-cc66-41fd-855a-72f4b31ceb83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "test_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbYhh_qvIUgr"
      },
      "source": [
        "Notre flux de travail sera le flux classique : dans un premier temps, nous présenterons au réseau de neurones les données d’entraînement, à savoir train_images et train_labels.\n",
        "Le réseau apprendra alors à associer les images à leurs étiquettes correspondantes.\n",
        "Enfin, nous demanderons au réseau de produire des prédictions pour test_images, et nous vérifierons si ces prédictions correspondent aux étiquettes contenues dans test_labels.\n",
        "\n",
        "Construisons maintenant notre réseau à l’aide de Keras — la documentation complète de Keras est disponible [here](https://keras.io)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "9gWZ0zKoIUgr"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(784, activation='relu', input_shape=(28 * 28,)))\n",
        "network.add(layers.Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWZD15eWIUgr"
      },
      "source": [
        "Le bloc de construction fondamental des réseaux de neurones est la « couche » (layer), un module de traitement de données que l’on peut concevoir comme un « filtre » appliqué aux données.\n",
        "Des données entrent et ressortent sous une forme plus utile. Plus précisément, les couches extraient des représentations à partir des données qui leur sont fournies — idéalement des représentations plus pertinentes pour le problème considéré.\n",
        "\n",
        "L’essentiel du deep learning consiste à enchaîner des couches simples, qui mettent en œuvre une forme de « distillation progressive des données ».\n",
        "Un modèle de deep learning est comparable à un tamis de traitement des données, constitué d’une succession de filtres de plus en plus raffinés — les couches.\n",
        "\n",
        "Une couche Dense signifie qu’il s’agit d’une couche de neurones densément connectée (également appelée entièrement connectée ou fully connected)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "oE9Dm4LPIUgr"
      },
      "outputs": [],
      "source": [
        "network.compile(optimizer='Adam',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bC1YibYeIUgr"
      },
      "source": [
        "\n",
        "Avant l’entraînement, nous allons prétraiter nos données en les remodelant afin qu’elles correspondent à la forme attendue par le réseau, et en les mettant à l’échelle de sorte que toutes les valeurs soient comprises dans l’intervalle [0, 1].\n",
        "\n",
        "Auparavant, par exemple, les images d’entraînement étaient stockées dans un tableau de forme (60000, 28, 28), de type uint8, avec des valeurs comprises dans l’intervalle [0, 255].\n",
        "Nous les transformons en un tableau de type float32, de forme (60000, 28 * 28), contenant des valeurs comprises entre 0 et 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1ayQcPfPIUgr"
      },
      "outputs": [],
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype('float32')/ 255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqBcLsNpIUgr"
      },
      "source": [
        "Nous devons également encoder catégoriquement les étiquettes :\n",
        "\n",
        "* Élément de liste\n",
        "* Élément de liste\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "nqBKeLEyIUgr"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyN21ZapIUgs"
      },
      "source": [
        "Nous sommes maintenant prêts à entraîner notre réseau, ce qui, dans Keras, se fait via un appel à la méthode `fit` du réseau :\n",
        "\n",
        "nous « ajustons » le modèle à ses données d’entraînement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpBW3LPdIUgs",
        "outputId": "940c3ceb-9b28-44fe-d1a2-208dba04657e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.8792 - loss: 0.4278\n",
            "Epoch 2/8\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9694 - loss: 0.1065\n",
            "Epoch 3/8\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9811 - loss: 0.0638\n",
            "Epoch 4/8\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9881 - loss: 0.0441\n",
            "Epoch 5/8\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9927 - loss: 0.0273\n",
            "Epoch 6/8\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9936 - loss: 0.0226\n",
            "Epoch 7/8\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9966 - loss: 0.0150\n",
            "Epoch 8/8\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9962 - loss: 0.0142\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b80fe4d3ec0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "network.fit(train_images, train_labels, epochs=8, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWRWvo7lIUgs"
      },
      "source": [
        "Deux grandeurs sont affichées pendant l'entraînement : la perte du réseau sur les données d'entraînement et sa précision sur ces mêmes données.\n",
        "\n",
        "Nous atteignons rapidement une précision de 0,989 (soit 98,9 %) sur les données d'entraînement. Vérifions maintenant que notre modèle fonctionne également bien sur l'ensemble de test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHfHjt9TIUgs",
        "outputId": "e880322e-0e94-44b8-b9a6-33b4a615b541"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9754 - loss: 0.0822\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = network.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29RWCa_IIUgs",
        "outputId": "ebff0e3e-37f0-48e1-9409-f30001841e4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_acc: 0.9800999760627747\n"
          ]
        }
      ],
      "source": [
        "print('test_acc:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pnh5zVgIIUgs"
      },
      "source": [
        "Notre précision sur l'ensemble de test s'avère être de 98,1 %, ce qui est nettement inférieur à la précision sur l'ensemble d'entraînement.\n",
        "\n",
        "Cet écart entre la précision d'entraînement et la précision de test est un exemple de « surapprentissage »,\n",
        "\n",
        "le fait que les modèles d'apprentissage automatique ont tendance à être moins performants sur de nouvelles données que sur leurs données d'entraînement.\n",
        "\n",
        "Ceci conclut notre tout premier exemple : vous venez de voir comment construire et entraîner un réseau de neurones pour classifier des chiffres manuscrits,\n",
        "\n",
        "en moins de 20 lignes de code Python.\n",
        "\n",
        "## Conclusions\n",
        "\n",
        "Voici les points à retenir de cet exemple :\n",
        "\n",
        "* Si vous cherchez à classer des points de données en N classes, votre réseau doit se terminer par une couche `Dense` de taille N.\n",
        "\n",
        "* Dans un problème de classification multiclasse à étiquette unique, votre réseau doit se terminer par une fonction d'activation `softmax`, afin de produire une\n",
        "distribution de probabilité sur les N classes de sortie.\n",
        "\n",
        "* L'entropie croisée catégorielle est presque toujours la fonction de perte à utiliser pour ce type de problèmes. Elle minimise la distance entre les distributions de probabilité produites par le réseau et la distribution réelle des cibles.\n",
        "\n",
        "* Il existe deux manières de gérer les étiquettes dans la classification multiclasse :\n",
        "\n",
        "* Encoder les étiquettes via un encodage catégoriel (également appelé encodage one-hot) et utiliser `categorical_crossentropy` comme fonction de perte (comme ici pour ce problème MNIST).\n",
        "\n",
        "* Encoder les étiquettes sous forme d'entiers et utiliser la fonction de perte `sparse_categorical_crossentropy`.\n",
        "\n",
        "* Si vous devez classer des données dans un grand nombre de catégories, vous devez éviter de créer des goulots d'étranglement dans votre réseau en utilisant des couches intermédiaires trop petites."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvatlHI6IUgs"
      },
      "source": [
        "Adapted by [François Septier](http://www.univ-ubs.fr/septier/) from the book of F. Chollet [Deep Learning with Python](https://www.amazon.fr/Deep-Learning-Python-Francois-Chollet/dp/1617294438)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVb4kS1mIUgs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}